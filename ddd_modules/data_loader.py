"""
æ•°æ®åŠ è½½æ¨¡å—ï¼šæ•°æ®åŠ è½½ã€éªŒè¯å’Œç‰¹å¾æå–
"""

import json
import sys
import os
import random
from pathlib import Path
from .config import TRAIN_END_DATE, REQUIRED_KLINE_LIMIT, REQUIRED_KLINE_COUNT, REQUIRED_WARMUP_PERIOD

# å¤„ç†é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__)).split('ddd_modules')[0].rstrip('/')
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from database.config import SessionLocal
    from database.models.stock_kline_day import StockKlineDay
    from sqlalchemy import func
    from src.backend.data_loader.kline_data_loader import load_stock_and_market_data
except ImportError:
    pass


def load_gp_features(mode: str) -> list:
    """
    ä» gp_features_config.json åŠ è½½ç‰¹å¾ç 
    
    Args:
        mode: 'sniper' | 'trend' | 'dual'
    
    Returns:
        ç‰¹å¾ç åˆ—è¡¨
    """
    # åœ¨ ddd_modules ç›®å½•å‘ä¸ŠæŸ¥æ‰¾ config ç›®å½•
    possible_paths = [
        Path(__file__).parent.parent / 'config' / 'gp_features_config.json',
        Path(__file__).parent / 'config' / 'gp_features_config.json',
    ]
    
    config_path = None
    for path in possible_paths:
        if path.exists():
            config_path = path
            break
    
    if config_path is None:
        raise FileNotFoundError(
            f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ gp_features_config.json\n"
            f"è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨äºé¡¹ç›®æ ¹ç›®å½•çš„ config/ ç›®å½•ä¸‹"
        )
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    if mode == 'sniper':
        features = config['sniper_mode']['features']
        print(f"ğŸ¯ ç‹™å‡»æ¨¡å¼ï¼šåŠ è½½ {len(features)} ä¸ªç‹™å‡»ç‰¹å¾")
    
    elif mode == 'trend':
        features = config['trend_mode']['features']
        print(f"ğŸ“ˆ è¶‹åŠ¿æ¨¡å¼ï¼šåŠ è½½ {len(features)} ä¸ªè¶‹åŠ¿ç‰¹å¾")
    
    elif mode == 'dual':
        sniper_features = config['sniper_mode']['features']
        trend_features = config['trend_mode']['features']
        features = list(dict.fromkeys(sniper_features + trend_features))
        print(f"âš–ï¸  åŒæ¨¡æ¨¡å¼ï¼šåŠ è½½ {len(sniper_features)} ä¸ªç‹™å‡» + {len(trend_features)} ä¸ªè¶‹åŠ¿ = {len(features)} ä¸ªæ€»ç‰¹å¾ï¼ˆå»é‡åï¼‰")
    
    else:
        raise ValueError(f"âŒ æ— æ•ˆçš„æ¨¡å¼: {mode}ï¼Œå¿…é¡»æ˜¯ 'sniper', 'trend' æˆ– 'dual'")
    
    return features


def get_valid_stocks(count=10):
    """è·å–æœ‰æ•ˆè‚¡ç¥¨åˆ—è¡¨ï¼ˆä¸¥æ ¼éªŒè¯ï¼‰"""
    db = SessionLocal()
    try:
        stock_config_path = Path(__file__).parent.parent / 'config' / 'hs300_zz500_zz1000.json'
        
        if not stock_config_path.exists():
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {stock_config_path}ï¼Œä½¿ç”¨æ•°æ®åº“æ‰€æœ‰è‚¡ç¥¨")
            use_all_stocks = True
            all_stock_codes = []
        else:
            with open(stock_config_path, 'r', encoding='utf-8') as f:
                stock_config = json.load(f)
            
            use_all_stocks = stock_config.get('use_all_stocks', False)
            
            if use_all_stocks:
                print(f"âœ… é…ç½®: use_all_stocks=true")
                print(f"   æ¨¡å¼: ä»æ•°æ®åº“è¯»å–æ‰€æœ‰è‚¡ç¥¨ï¼ˆè‡ªåŠ¨æ’é™¤STå’Œä¸å¯äº¤æ˜“è‚¡ç¥¨ï¼‰")
                
                from database.models.stock_info import StockInfo
                valid_stocks_query = db.query(StockInfo.stock_code).filter(
                    StockInfo.stock_name.notlike('%ST%'),
                    StockInfo.stock_name.notlike('%st%'),
                    StockInfo.is_tradable == True,
                    StockInfo.is_active == True
                ).all()
                valid_codes = set([code[0] for code in valid_stocks_query])
                
                all_codes_query = db.query(StockKlineDay.stock_code).filter(
                    StockKlineDay.period == 'day'
                ).distinct().all()
                
                all_codes_with_data = [code[0] for code in all_codes_query]
                all_stock_codes = [code for code in all_codes_with_data if code in valid_codes]
                
                print(f"   ä»æ•°æ®åº“: {len(all_codes_with_data)} åª -> æ’é™¤ST/ä¸å¯äº¤æ˜“: {len(all_stock_codes)} åª")
            else:
                print(f"âœ… é…ç½®: use_all_stocks=false")
                print(f"   æ¨¡å¼: ä»é…ç½®æ–‡ä»¶stock_codesåˆ—è¡¨è¯»å–")
                all_stock_codes = stock_config['stock_codes']
                print(f"   ä»é…ç½®æ–‡ä»¶: {len(all_stock_codes)} åªè‚¡ç¥¨")
        
        print(f"âœ… éšæœºæ‰“ä¹±è‚¡ç¥¨é¡ºåº...")
        stocks_list = all_stock_codes.copy()
        random.shuffle(stocks_list)
        
        print(f"âœ… å¼€å§‹éªŒè¯è‚¡ç¥¨ï¼ˆKçº¿>={REQUIRED_KLINE_COUNT}æ ¹ï¼Œæˆäº¤é‡100%å®Œæ•´ï¼‰...")
        valid_stocks = []
        
        checked_count = 0
        skipped_kline = 0
        skipped_volume = 0
        
        for stock_code in stocks_list:
            if len(valid_stocks) >= count:
                break
            
            checked_count += 1
            
            kline_count = db.query(func.count(StockKlineDay.id)).filter(
                StockKlineDay.stock_code == stock_code,
                StockKlineDay.period == 'day',
                StockKlineDay.trade_date <= TRAIN_END_DATE
            ).scalar()
            
            if kline_count < REQUIRED_KLINE_COUNT:
                skipped_kline += 1
                continue
            
            recent_klines = db.query(StockKlineDay).filter(
                StockKlineDay.stock_code == stock_code,
                StockKlineDay.period == 'day',
                StockKlineDay.trade_date <= TRAIN_END_DATE
            ).order_by(StockKlineDay.trade_date.desc()).limit(REQUIRED_KLINE_COUNT).all()
            
            if len(recent_klines) < REQUIRED_KLINE_COUNT:
                skipped_kline += 1
                continue
            
            invalid_volume_count = sum(
                1 for k in recent_klines 
                if k.volume is None or k.volume <= 0
            )
            
            if invalid_volume_count > 0:
                skipped_volume += 1
                continue
            
            valid_stocks.append(stock_code)
            
            if len(valid_stocks) % 50 == 0:
                print(f"   è¿›åº¦: {len(valid_stocks)}/{count} (å·²æ£€æŸ¥{checked_count}åª, Kçº¿ä¸è¶³{skipped_kline}åª, æˆäº¤é‡ä¸å…¨{skipped_volume}åª)", flush=True)
        
        print(f"âœ… æ‰¾åˆ°{len(valid_stocks)}åªæœ‰æ•ˆè‚¡ç¥¨")
        print(f"   æ€»å…±æ£€æŸ¥: {checked_count}åª")
        print(f"   Kçº¿ä¸è¶³: {skipped_kline}åª")
        print(f"   æˆäº¤é‡ä¸å…¨: {skipped_volume}åª")
        return valid_stocks
    finally:
        db.close()


def preextract_features(stock_data_cache, mode='dual', market_cache=None, random_sample=False):
    """
    é¢„æå–ç‰¹å¾ï¼ˆæ‰¹é‡å¤„ç†ï¼‰
    
    Args:
        stock_data_cache: è‚¡ç¥¨æ•°æ®ç¼“å­˜
        mode: 'dual'ï¼ˆåŒæ¨¡å¼ï¼‰ã€'sniper'ï¼ˆç‹™å‡»ï¼‰ã€'trend'ï¼ˆè¶‹åŠ¿ï¼‰
        market_cache: å¤§ç›˜æ•°æ®ç¼“å­˜å­—å…¸
        random_sample: æ˜¯å¦éšæœºæŠ½æ ·è®­ç»ƒæ•°æ®
    """
    if market_cache is None:
        market_cache = {}
    
    try:
        from gp_indicators_manager import GPIndicatorsManager
    except ImportError:
        GPIndicatorsManager = None
    
    preextracted_features = {}
    
    if GPIndicatorsManager is None:
        print("âš ï¸  GPIndicatorsManager æœªæ‰¾åˆ°ï¼Œè·³è¿‡ç‰¹å¾æå–")
        return preextracted_features, 0, 0
    
    gp_manager = GPIndicatorsManager(mode=mode)
    
    for idx, (stock_code, stock_data) in enumerate(stock_data_cache.items()):
        try:
            df_ohlcv_aligned, df_market = load_stock_and_market_data(
                stock_code=stock_code,
                end_date=TRAIN_END_DATE,
                limit=REQUIRED_KLINE_LIMIT,
                market_cache=market_cache,
                required_kline_count=REQUIRED_KLINE_COUNT,
                warmup_period=REQUIRED_WARMUP_PERIOD,
                random_sample=random_sample
            )
            
            if df_ohlcv_aligned is None:
                print(f"\r   âš ï¸  è‚¡ç¥¨ {stock_code} æ•°æ®åŠ è½½å¤±è´¥", flush=True)
                continue
            
            df_normalized = gp_manager.calculate_and_normalize(df_ohlcv_aligned, market_data=df_market)
            
            ohlcv_cols = ['open', 'high', 'low', 'close', 'volume']
            feature_cols = [col for col in df_normalized.columns if col not in ohlcv_cols]
            
            feature_data = {
                'features_all': df_normalized[feature_cols].values,
                'closes': df_ohlcv_aligned['close'].values,
                'highs': df_ohlcv_aligned['high'].values,
                'available_codes': feature_cols,
                'feature_to_var': {feat: feat for feat in feature_cols}
            }
            
            preextracted_features[stock_code] = feature_data
            
            if (idx + 1) % 5 == 0 or (idx + 1) == len(stock_data_cache):
                print(f"\r   â€¢ è¿›åº¦: {idx+1}/{len(stock_data_cache)} ({(idx+1)/len(stock_data_cache)*100:.1f}%)", end='', flush=True)
        
        except Exception as e:
            print(f"\r   âš ï¸  è‚¡ç¥¨ {stock_code} ç‰¹å¾æå–å¤±è´¥: {e}", flush=True)
            continue
    
    print()
    
    return preextracted_features, 0, 0
